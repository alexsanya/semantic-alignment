{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51587d7-9c6e-47d8-b7ed-dbd7498d51dd",
   "metadata": {},
   "source": [
    "# Semantic alignement with OpenAI text-embedding-3-small model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251118c5-b170-45b0-9759-800976bd31e0",
   "metadata": {},
   "source": [
    "## Step 1 - Build a dataset of native edition chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90077b-b3f0-4e1d-bb79-c7dbc0058999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_ru = spacy.load(\"ru_core_news_lg\")\n",
    "def split_into_chunks(text: str, max_chars: int = 300) -> list:\n",
    "    doc = nlp_ru(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for sent in sentences:\n",
    "        if len(current_chunk) + len(sent) <= max_chars:\n",
    "            current_chunk += (\" \" if current_chunk else \"\") + sent\n",
    "        else:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = sent\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a925a18-675c-418f-a7f4-4eeeb2f432e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def load_text_from_file(filepath: str) -> str:\n",
    "    return Path(filepath).read_text(encoding='utf-8')\n",
    "text_ru = load_text_from_file(\"text_ru.txt\")\n",
    "chunks_ru = split_into_chunks(text_ru.replace(\"\\n\", \" \"), max_chars=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7f7c2-395e-4241-9426-5c7ce5ae2e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(chunks_ru[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae0c15f-94f5-4e91-9af5-268a55e3a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4123761d-7895-49b8-96ae-0843233aca91",
   "metadata": {},
   "source": [
    "## Step 2 - Build a dataset of target edition chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92da82-a743-4537-8d88-f112b3453e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import es_core_news_sm\n",
    "nlp_es = es_core_news_sm.load()\n",
    "\n",
    "text=\"\"\"\n",
    "Lo envió a las autoridades acompañado de numerosos testimonios sobre sus experiencias\n",
    "y de varios pliegos de dibujos explicativos, al cuidado de un mensajero que atravesó la sierra,\n",
    "se extravió en pantanos desmesurados, remontó ríos tormentosos y estuvo a punto de perecer bajo el azote de las fieras,\n",
    "la desesperación y la peste, antes de conseguir una ruta de enlace con las mulas del correo.\n",
    "\"\"\"\n",
    "doc = nlp_es(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0cf4f-174b-45f9-ba5c-237165cf64c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import split_at\n",
    "def break_long_sentences(doc):\n",
    "    sublists = list(\n",
    "        \" \".join(line) for line in split_at(\n",
    "            [d.text for d in doc],\n",
    "            lambda x: x == \",\")\n",
    "    )\n",
    "    return [\n",
    "        chunk + ',' if i < len(sublists) - 1\n",
    "        else chunk for i, chunk in enumerate(sublists)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963ea0c-a04f-488b-8cd6-860fec16649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_long_sentences(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6965bd8-da79-4c2e-a7da-03449692d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_es_chunks(text: str) -> list:\n",
    "    doc = nlp_es(text)\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    parts = [break_long_sentences(s) for s in doc.sents]\n",
    "    return list(chain.from_iterable(parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8b1a5-e595-428b-a39f-4d0448a3a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_es = load_text_from_file(\"text_es.txt\")\n",
    "chunks_es = get_es_chunks(text_es.replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd67386-4109-405d-9324-7be16cae7387",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc8b1bf-dc08-4a6f-82a0-217718fd0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_es[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40072b09-d8bb-4638-9732-e29a7591a45b",
   "metadata": {},
   "source": [
    "## Step 3 - Embed and match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff146593-bea2-4123-bc5c-4a7a30e0e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from openai import AsyncOpenAI\n",
    "client = AsyncOpenAI(max_retries=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae18f00-ac90-4432-915b-3822bd268f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "async def get_embedding(text: str, model=\"text-embedding-3-small\", **kwargs) -> List[float]:\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    response = await client.embeddings.create(input=[text], model=model, **kwargs)\n",
    "\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88105059-0745-45da-b67c-56a4abb37cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = await get_embedding(chunks_ru[0])\n",
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae95357-e734-4bcb-be9e-5b1d937f555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3afe3f-9c28-41a7-8bd0-a16664c80400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31362da7-9f15-40f8-bcd0-6f3e03fe8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "display([chunks_ru[0], \" \".join(chunks_es[0:3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a223a1-c476-4998-ad8b-5aa30964609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(\n",
    "    await get_embedding(chunks_ru[0]),\n",
    "    await get_embedding(\" \".join(chunks_es[0:3]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee4e296-c026-4d32-ab40-6e2e3a2036b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "async def translate_russian_to_spanish(text: str) -> str:\n",
    "    result = await translator.translate(text, src=\"ru\", dest=\"es\")\n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a05b2f-9bb6-4460-ba3d-79b3c4119611",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(await get_embedding(\n",
    "    await translate_russian_to_spanish(chunks_ru[0])\n",
    "),\n",
    "    await get_embedding(\" \".join(chunks_es[0:3]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e210e8-0bf6-4033-b665-83486e289e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(await get_embedding(\n",
    "    await translate_russian_to_spanish(chunks_ru[1])),\n",
    "    await get_embedding(\" \".join(chunks_es[3:4]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329be78-aba8-476f-8e93-d80d29f302d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(await get_embedding(\n",
    "    await translate_russian_to_spanish(chunks_ru[1])),\n",
    "    await get_embedding(\" \".join(chunks_es[3:5]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00757e6-ab5d-4d6a-8c32-69f45202710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(await get_embedding(\n",
    "    await translate_russian_to_spanish(chunks_ru[1])),\n",
    "    await get_embedding(\" \".join(chunks_es[3:6]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5e274-1c00-4ab7-b455-4d7615b8f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display([chunks_ru[1], chunks_es[3:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c0bb5-ab5b-4641-9678-5743eeb6c9a9",
   "metadata": {},
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "317d0bfc-ae6c-4753-b81e-cee38faf118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ru_df = pd.DataFrame({ \"chunk\": chunks_ru })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e16d566b-e5f5-4a95-a623-bb9a391106d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d555f-9f29-4c69-991c-7e44a15b86b6",
   "metadata": {},
   "source": [
    "## Add column for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d4d50e0-b355-4d7b-a7f1-2b5704c2419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "# Wrapper to run async function in thread-friendly context\n",
    "async def translate_all(chunks, max_workers=10):\n",
    "    semaphore = asyncio.Semaphore(max_workers)\n",
    "    async def run_chunk(text):\n",
    "        async with semaphore:\n",
    "            return await translate_russian_to_spanish(text)\n",
    "\n",
    "    # Run in batches\n",
    "    tasks = [run_chunk(text) for text in chunks]\n",
    "    return await tqdm_asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "906197e4-392e-4445-a71d-d72e1d16c708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:02<00:00, 17.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run translation asynchronously and assign to new column\n",
    "translations = asyncio.run(translate_all(ru_df[\"chunk\"].tolist(), max_workers=20))\n",
    "ru_df[\"translation\"] = translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90a6489a-380e-42a5-bba3-b35a4a84db17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0f1308f-f688-474c-989d-bac0fa216af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Примитивная лаборатория располагала, не считая...</td>\n",
       "      <td>El laboratorio primitivo tenía, sin contar muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Кроме всего прочего, Мелькиадес дал образцы се...</td>\n",
       "      <td>Entre otras cosas, Melkiades dio muestras de s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Соблазненный простотой формулы получения золот...</td>\n",
       "      <td>Seducido por la simplicidad de la fórmula para...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chunk  \\\n",
       "48  Примитивная лаборатория располагала, не считая...   \n",
       "49  Кроме всего прочего, Мелькиадес дал образцы се...   \n",
       "50  Соблазненный простотой формулы получения золот...   \n",
       "\n",
       "                                          translation  \n",
       "48  El laboratorio primitivo tenía, sin contar muc...  \n",
       "49  Entre otras cosas, Melkiades dio muestras de s...  \n",
       "50  Seducido por la simplicidad de la fórmula para...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0444efdd-08aa-43f6-a455-ec994693b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df.to_pickle(\"ru_df_demo.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f008b21e-c739-4136-9cac-d58908f56baf",
   "metadata": {},
   "source": [
    "## Add embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92809eaf-5d1e-4417-b15d-6a6a88e560ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to run async function in thread-friendly context\n",
    "async def embed_all(chunks, max_workers=10):\n",
    "    semaphore = asyncio.Semaphore(max_workers)\n",
    "    async def run_chunk(text):\n",
    "        async with semaphore:\n",
    "            return await get_embedding(text)\n",
    "\n",
    "    # Run in batches\n",
    "    tasks = [run_chunk(text) for text in chunks]\n",
    "    return await tqdm_asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "852c3927-370f-4bb2-911e-18d8b3048f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 12.09it/s]\n"
     ]
    }
   ],
   "source": [
    "subset = ru_df[\"translation\"].tolist()\n",
    "embeddings = asyncio.run(embed_all(subset, max_workers=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e564fa4-e778-4faa-a21c-3ec511789b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df[\"embedding\"] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fbdc4ea-7223-4ebd-94e4-2c40f03a8f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3996a527-6081-4a88-b2fd-92f564edfd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>translation</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Много лет спустя, перед самым расстрелом, полк...</td>\n",
       "      <td>Muchos años después, justo antes del tiroteo, ...</td>\n",
       "      <td>[0.042346835136413574, -0.001678806496784091, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk  \\\n",
       "0  Много лет спустя, перед самым расстрелом, полк...   \n",
       "\n",
       "                                         translation  \\\n",
       "0  Muchos años después, justo antes del tiroteo, ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.042346835136413574, -0.001678806496784091, ...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5dd5a2e7-f2be-4b00-99e6-dd659e92ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df.to_pickle(\"ru_df_demo.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70af4a7d-1dff-4add-894c-ba3ae8de4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_matching_fragment(embed, pointer):\n",
    "    i=pointer+1\n",
    "    last_score = -1\n",
    "    while 1:\n",
    "        score = cosine_similarity(\n",
    "            embed,\n",
    "            await get_embedding(\" \".join(chunks_es[pointer:i]))\n",
    "        )\n",
    "        if (score < last_score):\n",
    "            break\n",
    "        last_score = score\n",
    "        i += 1\n",
    "    return (\" \".join(chunks_es[pointer:i-1]), i-1, last_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e2414aaf-8533-48a0-99b6-fbae53a115b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start_from(pointer, ru_chunk_index):\n",
    "    for (i, ru_embed) in enumerate(ru_df['embedding'][ru_chunk_index:], start=ru_chunk_index):\n",
    "        (es_chunk, new_pointer, score) = await get_matching_fragment(ru_embed, pointer)\n",
    "        retries = 0\n",
    "        while (score < 0.6) and (retries < 5):\n",
    "            print(f\"🔁 Retracing for fragment {i} | pointer {pointer} |️ {score}\")\n",
    "            pointer -= 1\n",
    "            (es_chunk, new_pointer, score) = await get_matching_fragment(ru_embed, pointer)\n",
    "            retries += 1\n",
    "        pointer += retries\n",
    "        retries = 0\n",
    "        while (score < 0.6) and (retries < 5):\n",
    "            print(f\"🔁 Retracing for fragment {i} | pointer {pointer} |️ {score}\")\n",
    "            pointer += 1\n",
    "            (es_chunk, new_pointer, score) = await get_matching_fragment(ru_embed, pointer)\n",
    "            retries += 1\n",
    "        if (score < 0.6):\n",
    "            ru_df.to_pickle(\"./merge/ru_df_matched.pkl\")\n",
    "            return pointer\n",
    "        pointer = new_pointer\n",
    "        ru_df.loc[i, \"match\"] = es_chunk\n",
    "        if i % 10 == 0:\n",
    "            ru_df.to_pickle(\"./merge/ru_df_matched.pkl\")\n",
    "            print(f\"✅ Data stored to file\")\n",
    "        print(f\"✅ fragment {i} |️ {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8fa4a103-774d-4b47-971e-4d767ebff6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data stored to file\n",
      "✅ fragment 0 |️ 0.8654028001839136\n",
      "✅ fragment 1 |️ 0.9073097628761001\n",
      "✅ fragment 2 |️ 0.7876713105387106\n",
      "✅ fragment 3 |️ 0.8038073793088721\n",
      "✅ fragment 4 |️ 0.7615130700959085\n",
      "🔁 Retracing for fragment 5 | pointer 25 |️ 0.5709271842365248\n",
      "✅ fragment 5 |️ 0.7094296078239161\n",
      "✅ fragment 6 |️ 0.8352721363690172\n",
      "✅ fragment 7 |️ 0.7991177630952013\n",
      "✅ fragment 8 |️ 0.8790443396951402\n",
      "✅ fragment 9 |️ 0.7123439494395828\n",
      "✅ Data stored to file\n",
      "✅ fragment 10 |️ 0.8143818241389978\n",
      "✅ fragment 11 |️ 0.8232202157218353\n",
      "✅ fragment 12 |️ 0.7488201304242075\n",
      "✅ fragment 13 |️ 0.7564914884271897\n",
      "✅ fragment 14 |️ 0.7398454437911969\n",
      "✅ fragment 15 |️ 0.7735542532823528\n",
      "✅ fragment 16 |️ 0.7252885476709303\n",
      "✅ fragment 17 |️ 0.8495790795365834\n",
      "✅ fragment 18 |️ 0.8422336902577091\n",
      "✅ fragment 19 |️ 0.8343837142285713\n",
      "✅ Data stored to file\n",
      "✅ fragment 20 |️ 0.7498534709395513\n",
      "✅ fragment 21 |️ 0.6668367141652842\n",
      "✅ fragment 22 |️ 0.7588848571155656\n",
      "✅ fragment 23 |️ 0.7315526070338915\n",
      "✅ fragment 24 |️ 0.8152837562644549\n",
      "✅ fragment 25 |️ 0.7917280904634557\n",
      "✅ fragment 26 |️ 0.7682676819441023\n",
      "✅ fragment 27 |️ 0.738301263491427\n",
      "✅ fragment 28 |️ 0.8539813378196687\n",
      "🔁 Retracing for fragment 29 | pointer 114 |️ 0.5964563047302951\n",
      "✅ fragment 29 |️ 0.6050610978187781\n",
      "🔁 Retracing for fragment 30 | pointer 117 |️ 0.33845686868248653\n",
      "🔁 Retracing for fragment 30 | pointer 116 |️ 0.3796013534359787\n",
      "🔁 Retracing for fragment 30 | pointer 115 |️ 0.36951431097284837\n",
      "🔁 Retracing for fragment 30 | pointer 114 |️ 0.36559540743925\n",
      "🔁 Retracing for fragment 30 | pointer 113 |️ 0.38426089798845947\n",
      "🔁 Retracing for fragment 30 | pointer 117 |️ 0.38442076876032666\n",
      "✅ Data stored to file\n",
      "✅ fragment 30 |️ 0.6550193398248859\n",
      "✅ fragment 31 |️ 0.8364766324796464\n",
      "✅ fragment 32 |️ 0.6377668980130433\n",
      "🔁 Retracing for fragment 33 | pointer 129 |️ 0.3897289352058642\n",
      "🔁 Retracing for fragment 33 | pointer 128 |️ 0.44831977859402544\n",
      "🔁 Retracing for fragment 33 | pointer 127 |️ 0.4168833552814182\n",
      "🔁 Retracing for fragment 33 | pointer 126 |️ 0.4334022616748834\n",
      "🔁 Retracing for fragment 33 | pointer 125 |️ 0.3967631366407224\n",
      "🔁 Retracing for fragment 33 | pointer 129 |️ 0.4211028612019262\n",
      "🔁 Retracing for fragment 33 | pointer 130 |️ 0.3513782884274587\n",
      "🔁 Retracing for fragment 33 | pointer 131 |️ 0.5766042862079036\n",
      "🔁 Retracing for fragment 33 | pointer 132 |️ 0.5564842791049227\n",
      "✅ fragment 33 |️ 0.6216224565226802\n",
      "✅ fragment 34 |️ 0.6976137092738819\n",
      "✅ fragment 35 |️ 0.7088507023982038\n",
      "✅ fragment 36 |️ 0.7656012227206329\n",
      "🔁 Retracing for fragment 37 | pointer 148 |️ 0.5644517999524998\n",
      "🔁 Retracing for fragment 37 | pointer 147 |️ 0.40658114319952976\n",
      "🔁 Retracing for fragment 37 | pointer 146 |️ 0.4551756211854185\n",
      "🔁 Retracing for fragment 37 | pointer 145 |️ 0.3771836903795648\n",
      "🔁 Retracing for fragment 37 | pointer 144 |️ 0.421222409702196\n",
      "🔁 Retracing for fragment 37 | pointer 148 |️ 0.396959559712021\n",
      "🔁 Retracing for fragment 37 | pointer 149 |️ 0.5519997124493783\n",
      "🔁 Retracing for fragment 37 | pointer 150 |️ 0.5434409550830733\n",
      "✅ fragment 37 |️ 0.6343412207535174\n",
      "✅ fragment 38 |️ 0.6669460971521155\n",
      "✅ fragment 39 |️ 0.8524653292998392\n",
      "✅ Data stored to file\n",
      "✅ fragment 40 |️ 0.6638459492259438\n",
      "✅ fragment 41 |️ 0.8962770004235179\n",
      "✅ fragment 42 |️ 0.8475577714241574\n",
      "✅ fragment 43 |️ 0.7478969575395603\n",
      "✅ fragment 44 |️ 0.7433796161920699\n",
      "✅ fragment 45 |️ 0.6710811242143276\n",
      "🔁 Retracing for fragment 46 | pointer 188 |️ 0.26508966432196374\n",
      "🔁 Retracing for fragment 46 | pointer 187 |️ 0.30723489239373397\n",
      "🔁 Retracing for fragment 46 | pointer 186 |️ 0.24574316574937713\n",
      "🔁 Retracing for fragment 46 | pointer 185 |️ 0.3228373205991397\n",
      "🔁 Retracing for fragment 46 | pointer 184 |️ 0.37109618957427254\n",
      "🔁 Retracing for fragment 46 | pointer 188 |️ 0.3773141807319017\n",
      "🔁 Retracing for fragment 46 | pointer 189 |️ 0.2443931130049236\n",
      "✅ fragment 46 |️ 0.8209780756354638\n",
      "🔁 Retracing for fragment 47 | pointer 196 |️ 0.5890311813821887\n",
      "✅ fragment 47 |️ 0.638644736917596\n",
      "🔁 Retracing for fragment 48 | pointer 198 |️ 0.3491339407248238\n",
      "🔁 Retracing for fragment 48 | pointer 197 |️ 0.48010486731053764\n",
      "🔁 Retracing for fragment 48 | pointer 196 |️ 0.3409674997216797\n",
      "🔁 Retracing for fragment 48 | pointer 195 |️ 0.3417297043196636\n",
      "🔁 Retracing for fragment 48 | pointer 194 |️ 0.40033952202864576\n",
      "🔁 Retracing for fragment 48 | pointer 198 |️ 0.39456701590442833\n",
      "🔁 Retracing for fragment 48 | pointer 199 |️ 0.34503215023798134\n",
      "🔁 Retracing for fragment 48 | pointer 200 |️ 0.3212302318678865\n",
      "🔁 Retracing for fragment 48 | pointer 201 |️ 0.4790974597287095\n",
      "🔁 Retracing for fragment 48 | pointer 202 |️ 0.5448393244366755\n"
     ]
    }
   ],
   "source": [
    "pointer = await start_from(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea17146-8692-4782-b3c9-462c6a295aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ae50f-764f-44e4-aa16-78d3c641a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6864f-ef38-4a9d-a4fd-38a8afee681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df.iloc[15:30][[\"chunk\", \"match\"]].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d0bf18-6215-40b0-a285-99913a14b259",
   "metadata": {},
   "source": [
    "## Converting to audio-book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e24d9fa5-ea5c-4bf8-a125-6095d489cabc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import texttospeech\n",
    "\n",
    "client = texttospeech.TextToSpeechClient(\n",
    "    client_options={\"quota_project_id\": \"dual-lingua\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "65b3b9c2-8117-45e0-834f-0b6c6ccdf7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_smm(matches):\n",
    "    result = '<speak>'\n",
    "    for match in matches:\n",
    "        result += f'<voice name=\"ru-RU-Wavenet-D\">{match[0]}</voice>'\n",
    "        result += f'<voice name=\"es-ES-Standard-B\">{match[1]}</voice>'\n",
    "    result += '</speak>'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c6fbea35-584c-4a32-b305-f1eb1a5ec6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = ru_df.iloc[15:18][[\"chunk\", \"match\"]].values.tolist()\n",
    "smm = list_to_smm(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a5c1df60-3a6f-4a07-b6b7-31f0f6bdbbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<speak><voice name=\"ru-RU-Wavenet-D\">Хосе Аркадио Буэндия, который не мог успокоиться после провала своей затеи с магнитами, тотчас сообразил, что это стекло можно использовать как боевое оружие. Мелькиадес снова попытался отговорить его.</voice><voice name=\"es-ES-Standard-B\">José Arcadio Buendía, que aún no acababa de consolarse por el fracaso de sus imanes, concibió la idea de utilizar aquel invento como un arma de guerra . Melquíades, otra vez, trató de disuadirlo .</voice><voice name=\"ru-RU-Wavenet-D\">Но в конечном счете цыган согласился отдать ему лупу в обмен на два магнита и три золотые колониальные монеты. Урсула рыдала от горя.</voice><voice name=\"es-ES-Standard-B\">Pero terrninó por aceptar los dos lingotes imantados y tres piezas de dinero colonial a cambio de la lupa . Úrsula lloró de consternación .</voice><voice name=\"ru-RU-Wavenet-D\">Эти деньги пришлось вытаскивать из сундучка с золотыми дублонами, которые ее отец копил всю свою жизнь, отказывая себе в лишнем куске, и которые она хранила в дальнем углу под кроватью в надежде, что подвернется счастливый случай для их удачного применения.</voice><voice name=\"es-ES-Standard-B\">Aquel dinero forrnaba parte de un cofre de monedas de oro que su padre había acumulado en toda una vida de privaciones, y que ella había enterrado debajo de la cama en espera de una buena ocasión para invertirlas .</voice></speak>'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "234d71ec-62ad-49c0-b880-6d237e9214e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smm_to_audio(ssml_text, output):\n",
    "    synthesis_input = texttospeech.SynthesisInput(ssml=ssml_text)\n",
    "    \n",
    "    # Choose a neutral voice (let Google pick based on lang tags)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"es-ES\",  # This is just a default, SSML will override per segment\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    "    )\n",
    "    \n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "    \n",
    "    response = client.synthesize_speech(\n",
    "        input=synthesis_input,\n",
    "        voice=voice,\n",
    "        audio_config=audio_config\n",
    "    )\n",
    "    \n",
    "    with open(output, \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "        print(\"Audio content written to \" + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "93d15bdf-4e60-4728-99e3-2682b4c0db18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio content written to story.mp3\n"
     ]
    }
   ],
   "source": [
    "smm_to_audio(smm, 'story.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f86a6-edd2-4701-979e-6cfd7f2560f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
